[
["index.html", "Data Science con R: Fundamentos y Aplicaciones ¡Bienvenidos!", " Data Science con R: Fundamentos y Aplicaciones BEST: Behavioral Economics &amp; Data Science Team 2019-01-25 ¡Bienvenidos! Nota: El libro se encuentra en etapa de desarrollo. Este libro ha sido elaborado por BEST. Hace unos años el término Data Science no era tan conocido ni utilizado por la comunidad internacional, y menos aún local (Perú). En realidad, era un término usado rara vez por los estadísticos y algunos miembros de la computación científica. Y es que nuestra sociedad ha evolucionado, y con ellos ciertas necesidades. La Ciencia de Datos ha venido para quedarse, y en cualquier profesión (economistas, psicólogos, biólogos, administradores, etc) y en cualquier industria (alimentaria, bancaria, servicios, etc) se ha vuelto vital para ser competitivo. Este libro es acerca de los fundamentos de la ciencia de datos y R, la lingua franca en estadística. Este libro es y será gratuito, siempre. "],
["introduccion.html", "Introducción Introducción para estudiantes Acerca del autor", " Introducción No sé R, tampoco R Studio ni Github y menos aún Data Science. Necesito aprenderlos pero soy nuevo y no sé tampoco programar ¿Qué puedo hacer? Si te preguntas a ti mismo esto, comienza con nuestra sección Introducción para estudiantes. Introducción para estudiantes Este libro asume no prerrequisitos: ni algebra, ni cálculo, ni experiencia previa programando. Este libro tiene como finalidad ofrecer a los estudiantes la capacidad de analizar data y responder preguntas usando data de forma profesional. ¿Qué aprenderé de este libro? Pasarás por aprender R, los comandos básicos y la lógica; entenderás los conceptos de Data Science y finalmente lo unirás todo para dominar los Fundamentos de Data Science con R Data Science. R. La investigación reproducible. Github. Acerca del autor ¡Aquí estoy yo! Arturo Chian Arturo Chian, FRM: Analista Senior - Scotiabank, Executive Director - BEST. Email: arturob.chian@gmail.com GitHub: https://github.com/arturochian Certified Financial Risk Manager por Global Association of Risk Professional (GARP), economista por la Universidad Nacional Mayor de San Marcos. Él es autor de 3 publicaciones “Quantitative Easing and Financial Instability: From Shadow Banking System to the Dealer of the Last Resort”, publicación del libro “International Monetary System: Past, Present, and Future” (2015), “Economía Conductual: Fundamentos y Aplicaciones” (2018) y “Data Science con R: Fundamentos y Aplicaciones” (2018). Especialista en Behavioral Finance &amp; Data Science. Actualmente es Director Ejecutivo de BEST, Analista Senior de Riesgos de Wealth Management en Scotiabank Perú, miembro consultivo de Circulo de Estudios Financieros y del Mercado de Capitales - UNMSM y columnista de la Revista Procapitales. Finalmente, es autor de diversos paquetes de R, incluyendo pemaps, INEIR, ENAHOR y SBSR. Él disfruta en sus ratos libres programar, leer libros de finanzas, psicología, estadística así como jugar videojuegos. "],
["prefacio.html", "Prefacio", " Prefacio Comencé aprendiendo R durante mi 3er año de pregrado de Economía (2012), cuando por casualidad revisé un blog donde decía que R era el mejor software de econometría y estadística, la lingua franca en estadística. Sin duda fue un amor a primera vista, un amor que, por razones del destino, no fue correspondido en los primeros meses… Me tomó tiempo desarrollar la habilidad de manejar R y entender lo que involucra estadística y Data Science de verdad, siendo mi tesis (2014), el año que la conquisté, o al menos alcancé un nivel bastante aceptable como para colaborar con paquetes utilizados actualmente como knitr, rmarkdown, htmlwidgets, etc. Mi reto era desarrollar una investigación a partir de la data de la SBS (Superintendencia de Banca y Seguros) y BCRP. ¿Qué logré dominar? Gráficos dinámicos, aplicaciones, reportes, creación de paquetes, entendimiento de los subsistemas de R… Y tuve la oportunidad única de ver cómo evolucionaron los paquetes como plyr, a un universo llamado actualmente tidyverse, o como knitr dio inicio al paquete rmarkdown. Durante más de 5 años, he venido evangelizando la importancia de la Ciencia de Datos, y el uso del software libre, R en particular. Estimado lector, espero que le sea de utilidad este libro y sobretodo lo disfrute. "],
["motivacion.html", "Motivación Estructura del libro Agradecimientos", " Motivación Information is the oil of the 21st century, and analytics is the combustion engine Peter Sondergaard, Senior Vice President at Gartner A la fecha nos encontramos en nueva revolución industrial, donde el nuevo petróleo es la información. ¿Quién no es usuario de Google, Facebook o Twitter? ¿Sabías que al leer estas líneas online o en pdf estás brindando datos también estás brindando información acerca de tus gustos? ¿Han escuchado o leído acerca del escándalo de Cambridge Analytica? ¿Han escuchado que la profesión más sexy de este siglo es ser Data Scientist? Este libro va dirigido a aquellos que están ingresando al mundo de la Ciencia de Datos, léase Data Science, y para aquellos que están conociendo la comunidad y la lingua franca en estadística, R. Esta publicación es y siempre será gratuita de forma online y es un libro en constante mejora para la comunidad. Estructura del libro Nota: El libro se encuentra en etapa de desarrollo. Agradecimientos Este libro es producto de una serie de personas y organizaciones a quien les debo mucho de mi crecimiento profesional y personal. En primer lugar, agradezco a BEST, por permitirme liderar este proyecto, cuya finalidad es generar conocimiento libre y de primer nivel. Agradezco también a mi Alma Mater, UNMSM, por los constantes retos y alegrías que me trajo a la vida y finalmente a mi familia, por apoyarme en cada momento de mi vida. Arturo Chian Lima, Peru "],
["intro.html", "Capítulo 1 Introducción 1.1 Data Science 1.2 R y RStudio 1.3 Git y Github", " Capítulo 1 Introducción 1.1 Data Science La Ciencia de Datos está de moda, eso es un hecho a nivel mundial, ¿pero cuántos realmente conocen qué significa? Hablar de Data Science en estas épocas es como hablar de sexo en la adolescencia, muchos dirán que ya saben, otros dirán que ya lo habrán hecho, pero realmente pocos saben de lo que están hablando. Lo mismo sucede con otros términos relacionado a la Ciencia de Datos como machine learning o big data. Comencemos entonces por definir la Ciencia de Datos. Es la disciplina que convierte la data en bruto (raw data) en conocimiento, entendimiento y en herramientas para comunicar. Para lograr ello, se necesita 3 habilidades de acuerdo al diagrama de Venn elaborado por Drew Conway: Conocimiento de Experto, Estadística y Métodos de hacking; este último lo podemos definir como la capacidad de resolver problemas con la data en bruto para convertirlo en data en limpio (tidy data). Dado la gran cantidad de datos que existe en internet y en datos no estructurados, la habilidad del hacking se vuelve una habilidad particularmente importante en estos días. Hace 50 años, John Tukey llamó a una reforma académica en estadística, a través de uno de los más importantes papers de esa época, llamado “The Future of Data Analysis”, donde señalaba la necesidad futura de una ciencia cuyo interés sea aprender de la data o análisis de datos. Hace unos 20 a 10 años, John Chamber, Jeff Wu, Bill Cleveland y Leo Breiman, dieron una serie de argumentos, de forma independiente sobre expandir los límites de la estadística teórica: Chambers enfatizaba la importancia de la preparación de datos, más que el modelaje estadístico; Breiman, prefería enfatizar la predicción antes que la inferencia; y Cleveland y Wu sugerían llamar a este nuevo campo Data Science por su estrecha relación a la data. Y fue así estimado lector, donde emerge un fenómeno: se abre paso a los programas de Data Science en las principales universidades del mundo: Berkeley, MIT, NYU, Michigan, Yale, y un gran etcétera. ¿Y qué retos enfrenta la Ciencia de Datos al día de hoy? Los retos de esta disciplina son diversos; sin embargo, a mi opinión, se centraría principalmente en el reto de comunicar de forma ética los avances de las ciencias y/o disciplinas de forma amigable a los usuarios en todo el mundo. Un mundo con mejor utilización de datos de forma ética, podría transformar al mundo a un mundo mejor… Para finalizar, como diría el tío Ben y Roosevelt: “Un gran poder, conlleva a una gran responsabilidad”. (Nota aclaratoria: Roosevelt fue el primero en decir esa frase; sin embargo, se popularizó con Spiderman). 1.2 R y RStudio Antes de iniciar debemos entender la diferencia entre R y RStudio. R es un lenguaje de programación con lo que corremos nuestros códigos (incluido este libro), mientras RStudio es un IDE (integrated development environment), el cual provee una interface para hacer más amigable programar en R e integrarlo con otras herramientas adicionales (git, github, python, C, etc.). R: Motor RStudio: Interface 1.2.1 Instalación de R y RStudio Para instalar primero necesitas descargar R y RStudio en tu laptop o desktop. Descarga R. Nota: Esto debes hacer primero. Elige tu versión de acuerdo a tu sistema operativo. Descarga RStudio. Elige tu versión de acuerdo a tu sistema operativo. 1.2.2 Usando R con RStudio ¿Se acuerdan de nuestra analogía señalada más arriba? Nosotros no interactuamos directamente con el motor cuando queremos utilizar un carro. Nosotros interactuamos y damos órdenes a través de la interface del vehículo, por lo que siempre estaremos utilizando RStudio. Para que quede claro: R: No abrir el motor RStudio: Usar la interface Después de abrir la interface (RStudio), deberías visualizar esto: RStudio 1.3 Git y Github Aparte de elegir el software con el cual trabajar Data Science, en nuestro caso R, hay otras elecciones muy importantes que elegir: (1) el sistema de control de versiones y (2) el servicio de alojamiento del sistema de control de versiones. Para los simples mortales, ¿Qué son ambos? Comencemos con un ejemplo. ¿Alguna vez han trabajado una macro, script o incluso una tesis, han realizado cambios y han querido regresar a la versión anterior? Podría apostar, casi sin temor a equivocarme, que han trabajado los clásicos “Versión 1”, “Versión 2”, “Versión Final” “Versión Final ésta es”, y así sucesivamente… para no perder una versión anterior. Pensado en ello, se desarrolló los sistemas para controlar versiones, un tema crítico, en especial si manejamos cientos o miles de líneas scripts y no sabes por cual error no está funcionando tu proyecto, en la nueva versión en que estás trabajando y quieres regresar a la versión estable anterior. Uno de los sistemas más utilizados en el mundo es Git, (que es distinto a Github) que tocaremos en breve… ¿Qué otros sistemas hay? Subversion, SourceSafe, TortoiseSVN, etc. Cada uno con sus pro y contra. ¿Entonces qué es Github? Github es el servicio de alojamiento más popular del sistema Git. ¿En cristiano qué significa? Es aquello que nos permite facilitar Git y trabajar nuestros proyectos de Data Science para evitar los clásicos Versión 1, Versión final, Versión final final, etc. Y Github no sólo es eso, sino una especie de red social de desarrolladores/empresas, donde éstos se conocen, trabajan proyectos en conjunto y se venden profesionalmente… Github es utilizado en el mundo para alojar diversos proyectos libres de Data Science y, en caso de querer mantener proyectos privados, se paga (es aquí donde funciona su modelo de negocio). Para usar la analogía: R a RStudio como Git a Github… Uno puede usar otro IDE como RStudio así como uno puede manejar otro empresa de servicios diferente a Github, pero RStudio y Github son los más populares. "],
["limpieza-de-datos.html", "Capítulo 2 Limpieza de Datos 2.1 Principios de Limpieza de datos 2.2 Principales problemas con base de datos sucias", " Capítulo 2 Limpieza de Datos La limpieza de datos es la parte dentro del proceso de la Ciencia de Datos que consume más tiempo. De acuerdo al paper de Dasu and Johnson (2003), el 80% del tiempo se consume en limpieza de datos. ¿Cómo aprender a limpiar data? Así como se aprende un nuevo lenguaje (alemán, francés, chino,etc), es necesario una cantidad importante de práctica y conocer los principios de la limpieza de datos 2.1 Principios de Limpieza de datos Los principios de limpieza de datos proveen un estándar para limpiar la data para no reinventar la rueda cada vez que tratamos de limpiar base de datos. La idea de la bases de datos limpias es hacer el análisis de datos más fácil, permitiendo enfocarnos en entender el problema y no la logística de la data. Una base de datos limpia tiene las siguientes características: 1.- Cada variable forma una columna. 2.- Cada observación forma una fila. 3.- Cada tipo de unidad observacional forma una tabla. 2.2 Principales problemas con base de datos sucias 2.2.1 Las columnas son valores y no nombres de valores 2.2.2 Múltipes variables están almacenadas en una columna 2.2.3 Variables están almacenadas en filas y columnas 2.2.4 Múltipes tipos de unidades observacionales están almacenadas en la misma tabla 2.2.5 Una sola unidad observacional está almacenada en múltiples tablas ¡Próximamente podrás utilizar ejercicios para practicar este skill tan importante con data real de la SBS, SMV, INEI, BCRP, mensajes presindenciales y muchas otras fuentes! "],
["analisis-exploratorio.html", "Capítulo 3 Análisis Exploratorio", " Capítulo 3 Análisis Exploratorio "],
["analisis-inferencial.html", "Capítulo 4 Análisis Inferencial", " Capítulo 4 Análisis Inferencial "],
["machine-learning.html", "Capítulo 5 Machine Learning", " Capítulo 5 Machine Learning "],
["comunicando-resultados.html", "Capítulo 6 Comunicando Resultados", " Capítulo 6 Comunicando Resultados Aquí hablaremos más gráficos dinámicos, shinys y Rmarkdown! "],
["temas-suplementarios.html", "Capítulo 7 Temas suplementarios", " Capítulo 7 Temas suplementarios "]
]
